{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "fileName = '/Users/erichsu/LING406/yelp_dataset_challenge_academic_dataset/yelp_academic_dataset_review.json'\n",
    "\n",
    "data = []\n",
    "count = 0\n",
    "with open(fileName) as f:\n",
    "    for line in f:\n",
    "        if count<1000000:\n",
    "            count += 1\n",
    "            data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def review_to_wordlist( review, remove_stopwords=False ):\n",
    "    # Function to convert a document to a sequence of words,\n",
    "    # optionally removing stop words.  Returns a list of words.\n",
    "    #\n",
    "    # 1. Remove HTML\n",
    "    review_text = BeautifulSoup(review).get_text()\n",
    "    #  \n",
    "    # 2. Remove non-letters\n",
    "    review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
    "    #\n",
    "    # 3. Convert words to lower case and split them\n",
    "    words = review_text.lower().split()\n",
    "    #\n",
    "    # 4. Optionally remove stop words (false by default)\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "    #\n",
    "    # 5. Return a list of words\n",
    "    return(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.probability import *\n",
    "\n",
    "import nltk.data\n",
    "# Load the punkt tokenizer\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "# Define a function to split a review into parsed sentences\n",
    "def review_to_sentences( review, tokenizer, remove_stopwords=False ):\n",
    "    # Function to split a review into parsed sentences. Returns a \n",
    "    # list of sentences, where each sentence is a list of words\n",
    "    #\n",
    "    # 1. Use the NLTK tokenizer to split the paragraph into sentences\n",
    "    raw_sentences = tokenizer.tokenize(review.strip())\n",
    "    #\n",
    "    # 2. Loop over each sentence\n",
    "    sentences = []\n",
    "    for raw_sentence in raw_sentences:\n",
    "        # If a sentence is empty, skip it\n",
    "        if len(raw_sentence) > 0:\n",
    "            # Otherwise, call review_to_wordlist to get a list of words\n",
    "            sentences.append( review_to_wordlist( raw_sentence, \\\n",
    "              remove_stopwords ))\n",
    "    #\n",
    "    # Return the list of sentences (each sentence is a list of words,\n",
    "    # so this returns a list of lists\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences = review_to_sentences(data[1]['text'], tokenizer, True)\n",
    "fd1 = nltk.FreqDist(sentences[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({u'takes': 1, u'get': 1, u'calling': 1, u'hours': 1, u'answer': 1, u'repeated': 1, u'usually': 1})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "reviews = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "goodReviews = reviews[reviews['stars']>3].reset_index()\n",
    "badReviews = reviews[reviews['stars']<=3].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def frequencyList(corpus):\n",
    "    freq = {}\n",
    "    for i in range(len(corpus)):\n",
    "        sentences = review_to_sentences(data[i]['text'], tokenizer, True)\n",
    "        for s in sentences:\n",
    "            for w in s:\n",
    "                if freq.has_key(w):\n",
    "                    freq[w] = freq[w] + 1\n",
    "                else:\n",
    "                    freq[w] = 1\n",
    "    return freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/erichsu/anaconda/lib/python2.7/site-packages/bs4/__init__.py:182: UserWarning: \".\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  '\"%s\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.' % markup)\n",
      "/Users/erichsu/anaconda/lib/python2.7/site-packages/bs4/__init__.py:189: UserWarning: \"http://eatinginpittsburgh.com/2011/02/11/coffee-pittsburgh-part-2/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n",
      "/Users/erichsu/anaconda/lib/python2.7/site-packages/bs4/__init__.py:189: UserWarning: \"http://eatinginpittsburgh.com/2010/07/07/ive-got-an-itch-for-kitsch-quiet-storm-in-bloomfield/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n",
      "/Users/erichsu/anaconda/lib/python2.7/site-packages/bs4/__init__.py:189: UserWarning: \"http://www.edgewooddentalassociates.com/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n",
      "/Users/erichsu/anaconda/lib/python2.7/site-packages/bs4/__init__.py:189: UserWarning: \"http://www.atrias.com/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n",
      "/Users/erichsu/anaconda/lib/python2.7/site-packages/bs4/__init__.py:189: UserWarning: \"http://en.wikipedia.org/wiki/Bus_bunching\n",
      "3.\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n",
      "/Users/erichsu/anaconda/lib/python2.7/site-packages/bs4/__init__.py:189: UserWarning: \"http://www.wellbuzz.com/dr-oz-beauty/dr-oz-pedicure-bacterial-infections-dry-pedicure-haircut-ringworm/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n",
      "/Users/erichsu/anaconda/lib/python2.7/site-packages/bs4/__init__.py:189: UserWarning: \"http://www.priceline.com.\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n",
      "/Users/erichsu/anaconda/lib/python2.7/site-packages/bs4/__init__.py:189: UserWarning: \"http://tlcwingsandgrill.com/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n",
      "/Users/erichsu/anaconda/lib/python2.7/site-packages/bs4/__init__.py:189: UserWarning: \"http://www.wcnc.com/on-tv/Larry-learns-that-curling-is-year-round-90346659.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n",
      "/Users/erichsu/anaconda/lib/python2.7/site-packages/bs4/__init__.py:189: UserWarning: \"http://www.mcninchhouserestaurant.com/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n",
      "/Users/erichsu/anaconda/lib/python2.7/site-packages/bs4/__init__.py:189: UserWarning: \"http://www.yelp.com/biz/matts-chicago-dog-charlotte#hrid:Kn7dQhdcPMfAv-UTRkQjxA.\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n",
      "/Users/erichsu/anaconda/lib/python2.7/site-packages/bs4/__init__.py:182: UserWarning: \"..\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  '\"%s\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.' % markup)\n",
      "/Users/erichsu/anaconda/lib/python2.7/site-packages/bs4/__init__.py:189: UserWarning: \"http://evergreenstudio1.com/blog/?p=3960\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n",
      "/Users/erichsu/anaconda/lib/python2.7/site-packages/bs4/__init__.py:189: UserWarning: \"http://trifoodiemd.blogspot.com/2013/01/carpe-diem-restaurant.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n",
      "/Users/erichsu/anaconda/lib/python2.7/site-packages/bs4/__init__.py:189: UserWarning: \"http://www.montereybayaquarium.org//cr/SeafoodWatch/web/sfw_factsheet.aspx?gid=18\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n",
      "/Users/erichsu/anaconda/lib/python2.7/site-packages/bs4/__init__.py:189: UserWarning: \"http://www.charlotteobserver.com/2011/11/15/2777229/council-makes-bofa-sole-source.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n",
      "/Users/erichsu/anaconda/lib/python2.7/site-packages/bs4/__init__.py:189: UserWarning: \"http://www.reuters.com/article/2013/04/09/entertainment-us-usa-cuba-beyonce-idUSBRE93600V20130409\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n",
      "/Users/erichsu/anaconda/lib/python2.7/site-packages/bs4/__init__.py:189: UserWarning: \"http://www.bombaygrille.com/charlottemenu.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n",
      "/Users/erichsu/anaconda/lib/python2.7/site-packages/bs4/__init__.py:189: UserWarning: \"http://www.thegreenlanternrestaurant.com.\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n",
      "/Users/erichsu/anaconda/lib/python2.7/site-packages/bs4/__init__.py:189: UserWarning: \"http://www.universityclubphoenix.com/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n",
      "/Users/erichsu/anaconda/lib/python2.7/site-packages/bs4/__init__.py:189: UserWarning: \"http://www.tastykake.com/aboutus/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n",
      "/Users/erichsu/anaconda/lib/python2.7/site-packages/bs4/__init__.py:189: UserWarning: \"http://www.yelp.com/biz_photos/hU6sN5r6vayqm_RMgvPGOQ?select=Y6gF0oMs3bwU8vjC7Kymsg\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n",
      "/Users/erichsu/anaconda/lib/python2.7/site-packages/bs4/__init__.py:189: UserWarning: \"http://www.restaurantnoca.com/Menu/Specials/NOCA_Nobuo_August_Menu.pdf\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n",
      "/Users/erichsu/anaconda/lib/python2.7/site-packages/bs4/__init__.py:189: UserWarning: \"http://www.ryanspet.com/ryanspet/default.asp?\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n",
      "/Users/erichsu/anaconda/lib/python2.7/site-packages/bs4/__init__.py:189: UserWarning: \"http://www.sonicdrivein.com/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n",
      "/Users/erichsu/anaconda/lib/python2.7/site-packages/bs4/__init__.py:189: UserWarning: \"http://www.teamcentennial.com/inventory.asp\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n",
      "/Users/erichsu/anaconda/lib/python2.7/site-packages/bs4/__init__.py:189: UserWarning: \"http://www.yelp.com/biz/pho-nhat-tempe\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n",
      "/Users/erichsu/anaconda/lib/python2.7/site-packages/bs4/__init__.py:189: UserWarning: \"http://www.invisiblechildren.com/home.php\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n",
      "/Users/erichsu/anaconda/lib/python2.7/site-packages/bs4/__init__.py:189: UserWarning: \"http://www.attorneysteve.net\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n",
      "/Users/erichsu/anaconda/lib/python2.7/site-packages/bs4/__init__.py:189: UserWarning: \"http://www.carmeloricarde.com/my-cakes-so-far/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n",
      "/Users/erichsu/anaconda/lib/python2.7/site-packages/bs4/__init__.py:189: UserWarning: \"http://www.carmeloricarde.com/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n",
      "/Users/erichsu/anaconda/lib/python2.7/site-packages/bs4/__init__.py:189: UserWarning: \"http://www.carmeloricarde.com/about/cake/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n",
      "/Users/erichsu/anaconda/lib/python2.7/site-packages/bs4/__init__.py:189: UserWarning: \"http://www.azpbs.org/checkplease/segments/restaurant.php?id=5441&utm_source=January+25th&utm_campaign=Check+Please!&utm_medium=socialshare\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n",
      "/Users/erichsu/anaconda/lib/python2.7/site-packages/bs4/__init__.py:189: UserWarning: \"http://www.locker13.com/.\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n",
      "/Users/erichsu/anaconda/lib/python2.7/site-packages/bs4/__init__.py:189: UserWarning: \"http://louis-vuitton.pissedconsumer.com\n",
      "\n",
      "http://www.consumeraffairs.com/retail/louis_vuitton.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n",
      "/Users/erichsu/anaconda/lib/python2.7/site-packages/bs4/__init__.py:189: UserWarning: \"http://www.readwriteweb.com/archives/google_ceo_suggests_you_change_your_name_to_escape.php\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n",
      "/Users/erichsu/anaconda/lib/python2.7/site-packages/bs4/__init__.py:189: UserWarning: \"http://www.therelaxationspa.com/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n",
      "/Users/erichsu/anaconda/lib/python2.7/site-packages/bs4/__init__.py:189: UserWarning: \"http://www.phoenixflowershops.com/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n",
      "/Users/erichsu/anaconda/lib/python2.7/site-packages/bs4/__init__.py:189: UserWarning: \"http://www.maricopa.gov/pets/vaccinations.aspx\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n",
      "/Users/erichsu/anaconda/lib/python2.7/site-packages/bs4/__init__.py:189: UserWarning: \"http://www.azcentral.com/thingstodo/events/articles/2010/09/23/20100923phoenix-le-bellezze-ditalia-car-show.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n",
      "/Users/erichsu/anaconda/lib/python2.7/site-packages/bs4/__init__.py:189: UserWarning: \"http://www.linkedin.com/today/post/article/20130604134550-284615-15-statistics-that-should-change-the-business-world-but-haven-t\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n",
      "/Users/erichsu/anaconda/lib/python2.7/site-packages/bs4/__init__.py:189: UserWarning: \"http://www.spinatospizza.com/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n",
      "/Users/erichsu/anaconda/lib/python2.7/site-packages/bs4/__init__.py:189: UserWarning: \"http://www.youtube.com/watch?v=K6BlOkpdkg8&feature=related\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n"
     ]
    }
   ],
   "source": [
    "GoodFreq = frequencyList(goodReviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BadFreq = frequencyList(badReviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "sorted_g = sorted(GoodFreq.items(), key=operator.itemgetter(1))\n",
    "sorted_b = sorted(BadFreq.items(), key=operator.itemgetter(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted_g.reverse()\n",
    "sorted_b.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_feats(words):\n",
    "    return dict([(word, True) for word in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk.classify.util\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "\n",
    "def word_feats(words):\n",
    "    return dict([(word, True) for word in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "goodReview = []\n",
    "badReview = []\n",
    "for i in range(len(data)):\n",
    "    if data[i]['stars']>3:\n",
    "        goodReview.append(data[i]['text'])\n",
    "    else:\n",
    "        badReview.append(data[i]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "posfeats = [(word_feats(review_to_wordlist(f)), 'pos') for f in goodReview]\n",
    "negfeats = [(word_feats(review_to_wordlist(f)), 'neg') for f in badReview]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 74999 instances, test on 25001 instances\n"
     ]
    }
   ],
   "source": [
    "negcutoff = len(negfeats)*3/4\n",
    "poscutoff = len(posfeats)*3/4\n",
    " \n",
    "trainfeats = negfeats[:negcutoff] + posfeats[:poscutoff]\n",
    "testfeats = negfeats[negcutoff:] + posfeats[poscutoff:]\n",
    "print 'train on %d instances, test on %d instances' % (len(trainfeats), len(testfeats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.508659653614\n",
      "Most Informative Features\n",
      "          unprofessional = True              neg : pos    =     57.5 : 1.0\n",
      "                  argued = True              neg : pos    =     39.7 : 1.0\n",
      "             inexcusable = True              neg : pos    =     37.7 : 1.0\n",
      "           disrespectful = True              neg : pos    =     33.7 : 1.0\n",
      "                 mumbled = True              neg : pos    =     31.5 : 1.0\n",
      "            unappetizing = True              neg : pos    =     26.8 : 1.0\n",
      "                   livid = True              neg : pos    =     26.6 : 1.0\n",
      "              flavorless = True              neg : pos    =     26.1 : 1.0\n",
      "                    scam = True              neg : pos    =     24.6 : 1.0\n",
      "                 visibly = True              neg : pos    =     24.1 : 1.0\n",
      "                  rudest = True              neg : pos    =     24.1 : 1.0\n",
      "                appalled = True              neg : pos    =     24.1 : 1.0\n",
      "                  mildew = True              neg : pos    =     22.9 : 1.0\n",
      "              violations = True              neg : pos    =     22.9 : 1.0\n",
      "                disgrace = True              neg : pos    =     22.9 : 1.0\n",
      "                   sysco = True              neg : pos    =     21.6 : 1.0\n",
      "         inconveniencing = True              neg : pos    =     21.6 : 1.0\n",
      "           uninteresting = True              neg : pos    =     21.6 : 1.0\n",
      "                 passive = True              neg : pos    =     21.6 : 1.0\n",
      "                   stunk = True              neg : pos    =     21.6 : 1.0\n",
      "               appalling = True              neg : pos    =     21.1 : 1.0\n",
      "               congealed = True              neg : pos    =     21.1 : 1.0\n",
      "               redeeming = True              neg : pos    =     21.0 : 1.0\n",
      "                 listens = True              pos : neg    =     20.7 : 1.0\n",
      "               unethical = True              neg : pos    =     20.4 : 1.0\n",
      "                  stench = True              neg : pos    =     19.9 : 1.0\n",
      "               disgusted = True              neg : pos    =     19.4 : 1.0\n",
      "            unacceptable = True              neg : pos    =     19.3 : 1.0\n",
      "                  wendys = True              neg : pos    =     19.2 : 1.0\n",
      "             unorganized = True              neg : pos    =     19.2 : 1.0\n",
      "                 dispute = True              neg : pos    =     19.2 : 1.0\n",
      "               gossiping = True              neg : pos    =     19.2 : 1.0\n",
      "                inedible = True              neg : pos    =     19.0 : 1.0\n",
      "             inattentive = True              neg : pos    =     19.0 : 1.0\n",
      "                  reeked = True              neg : pos    =     18.9 : 1.0\n",
      "                   roach = True              neg : pos    =     18.8 : 1.0\n",
      "                  rudely = True              neg : pos    =     18.4 : 1.0\n",
      "                shameful = True              neg : pos    =     17.9 : 1.0\n",
      "             haphazardly = True              neg : pos    =     17.9 : 1.0\n",
      "                 decency = True              neg : pos    =     17.9 : 1.0\n",
      "                  insult = True              neg : pos    =     17.2 : 1.0\n",
      "                   worst = True              neg : pos    =     17.1 : 1.0\n",
      "                 refunds = True              neg : pos    =     16.7 : 1.0\n",
      "                 accused = True              neg : pos    =     16.7 : 1.0\n",
      "                 roaches = True              neg : pos    =     16.7 : 1.0\n",
      "                  soured = True              neg : pos    =     16.7 : 1.0\n",
      "                  refund = True              neg : pos    =     16.7 : 1.0\n",
      "                 slopped = True              neg : pos    =     16.7 : 1.0\n",
      "                 insults = True              neg : pos    =     16.7 : 1.0\n",
      "              advertises = True              neg : pos    =     16.7 : 1.0\n",
      "                  aweful = True              neg : pos    =     16.7 : 1.0\n",
      "               tasteless = True              neg : pos    =     16.4 : 1.0\n",
      "            incompetence = True              neg : pos    =     15.9 : 1.0\n",
      "                drooling = True              pos : neg    =     15.6 : 1.0\n",
      "               reimburse = True              neg : pos    =     15.5 : 1.0\n",
      "               notifying = True              neg : pos    =     15.5 : 1.0\n",
      "              reiterated = True              neg : pos    =     15.5 : 1.0\n",
      "                 hostage = True              neg : pos    =     15.5 : 1.0\n",
      "            disrespected = True              neg : pos    =     15.5 : 1.0\n",
      "                 abysmal = True              neg : pos    =     15.1 : 1.0\n",
      "              disgusting = True              neg : pos    =     14.9 : 1.0\n",
      "               insulting = True              neg : pos    =     14.6 : 1.0\n",
      "                  filthy = True              neg : pos    =     14.6 : 1.0\n",
      "           inconsiderate = True              neg : pos    =     14.5 : 1.0\n",
      "                     ehh = True              neg : pos    =     14.5 : 1.0\n",
      "                 slowest = True              neg : pos    =     14.3 : 1.0\n",
      "                  glared = True              neg : pos    =     14.2 : 1.0\n",
      "                 tainted = True              neg : pos    =     14.2 : 1.0\n",
      "                 saddens = True              neg : pos    =     14.2 : 1.0\n",
      "                  apathy = True              neg : pos    =     14.2 : 1.0\n",
      "              tablespoon = True              neg : pos    =     14.2 : 1.0\n",
      "           justification = True              neg : pos    =     14.2 : 1.0\n",
      "               shriveled = True              neg : pos    =     14.2 : 1.0\n",
      "               cockroach = True              neg : pos    =     14.0 : 1.0\n",
      "             incompetent = True              neg : pos    =     13.9 : 1.0\n",
      "                  subpar = True              neg : pos    =     13.8 : 1.0\n",
      "                accosted = True              neg : pos    =     13.7 : 1.0\n",
      "               voicemail = True              neg : pos    =     13.4 : 1.0\n",
      "                 refused = True              neg : pos    =     13.4 : 1.0\n",
      "               irritated = True              neg : pos    =     13.2 : 1.0\n",
      "              humiliated = True              neg : pos    =     13.0 : 1.0\n",
      "                 tantrum = True              neg : pos    =     13.0 : 1.0\n",
      "                downhill = True              neg : pos    =     13.0 : 1.0\n",
      "                 alleged = True              neg : pos    =     13.0 : 1.0\n",
      "               repulsive = True              neg : pos    =     13.0 : 1.0\n",
      "            deteriorated = True              neg : pos    =     13.0 : 1.0\n",
      "                 thieves = True              neg : pos    =     13.0 : 1.0\n",
      "                bacteria = True              neg : pos    =     13.0 : 1.0\n",
      "                  fazoli = True              neg : pos    =     13.0 : 1.0\n",
      "                 tricked = True              neg : pos    =     13.0 : 1.0\n",
      "                     wks = True              neg : pos    =     13.0 : 1.0\n",
      "               increases = True              neg : pos    =     13.0 : 1.0\n",
      "                 pitiful = True              neg : pos    =     13.0 : 1.0\n",
      "                unedible = True              neg : pos    =     13.0 : 1.0\n",
      "                   huffy = True              neg : pos    =     13.0 : 1.0\n",
      "                  hatred = True              neg : pos    =     13.0 : 1.0\n",
      "                 blaming = True              neg : pos    =     13.0 : 1.0\n",
      "               canceling = True              neg : pos    =     13.0 : 1.0\n",
      "                    liar = True              neg : pos    =     12.4 : 1.0\n",
      "                diarrhea = True              neg : pos    =     12.4 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier = NaiveBayesClassifier.train(trainfeats)\n",
    "print 'accuracy:', nltk.classify.util.accuracy(classifier, testfeats)\n",
    "classifier.show_most_informative_features(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.classify.scikitlearn import SklearnClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.classify import SklearnClassifier\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([('tfidf', TfidfTransformer()),\n",
    "                     ('chi2', SelectKBest(chi2, k=1000)),\n",
    "                     ('nb', MultinomialNB())])\n",
    "classif = SklearnClassifier(MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SklearnClassifier(MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classif.train(trainfeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.838446462142\n"
     ]
    }
   ],
   "source": [
    "classifier = classif.train(trainfeats)\n",
    "print 'accuracy:', nltk.classify.util.accuracy(classifier, testfeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60961"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(GoodFreq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
